{
  "model": "gpt2-medium",
  "rank_schedule": "schedules/gpt2-medium_budget16_CORRECTED.csv",
  "uniform_rank": 0,
  "peft_used": true,
  "peft_meta": {
    "adapters": {
      "r64": {
        "r": 64,
        "modules": [
          "transformer.h.0.attn.c_attn",
          "transformer.h.1.attn.c_attn",
          "transformer.h.10.attn.c_attn",
          "transformer.h.11.attn.c_attn",
          "transformer.h.12.attn.c_attn",
          "transformer.h.13.attn.c_attn",
          "transformer.h.15.attn.c_attn",
          "transformer.h.17.attn.c_attn",
          "transformer.h.18.attn.c_attn",
          "transformer.h.19.attn.c_attn",
          "transformer.h.2.attn.c_attn",
          "transformer.h.20.attn.c_attn",
          "transformer.h.21.attn.c_proj",
          "transformer.h.22.attn.c_proj",
          "transformer.h.23.attn.c_attn",
          "transformer.h.23.attn.c_proj",
          "transformer.h.3.attn.c_attn",
          "transformer.h.4.attn.c_attn",
          "transformer.h.5.attn.c_attn",
          "transformer.h.6.attn.c_attn",
          "transformer.h.7.attn.c_attn",
          "transformer.h.8.attn.c_attn",
          "transformer.h.9.attn.c_attn"
        ]
      },
      "r61": {
        "r": 61,
        "modules": [
          "transformer.h.20.attn.c_proj"
        ]
      },
      "r60": {
        "r": 60,
        "modules": [
          "transformer.h.16.attn.c_attn",
          "transformer.h.19.attn.c_proj"
        ]
      },
      "r56": {
        "r": 56,
        "modules": [
          "transformer.h.18.attn.c_proj"
        ]
      },
      "r55": {
        "r": 55,
        "modules": [
          "transformer.h.17.attn.c_proj"
        ]
      },
      "r54": {
        "r": 54,
        "modules": [
          "transformer.h.16.attn.c_proj"
        ]
      },
      "r52": {
        "r": 52,
        "modules": [
          "transformer.h.15.attn.c_proj",
          "transformer.h.22.attn.c_attn"
        ]
      },
      "r51": {
        "r": 51,
        "modules": [
          "transformer.h.10.attn.c_proj",
          "transformer.h.11.attn.c_proj",
          "transformer.h.9.attn.c_proj"
        ]
      },
      "r50": {
        "r": 50,
        "modules": [
          "transformer.h.12.attn.c_proj",
          "transformer.h.14.attn.c_proj"
        ]
      },
      "r49": {
        "r": 49,
        "modules": [
          "transformer.h.13.attn.c_proj"
        ]
      },
      "r48": {
        "r": 48,
        "modules": [
          "transformer.h.1.attn.c_proj",
          "transformer.h.8.attn.c_proj"
        ]
      },
      "r47": {
        "r": 47,
        "modules": [
          "transformer.h.21.attn.c_attn"
        ]
      },
      "r45": {
        "r": 45,
        "modules": [
          "transformer.h.7.attn.c_proj"
        ]
      },
      "r44": {
        "r": 44,
        "modules": [
          "transformer.h.6.attn.c_proj"
        ]
      },
      "r42": {
        "r": 42,
        "modules": [
          "transformer.h.14.attn.c_attn"
        ]
      },
      "r41": {
        "r": 41,
        "modules": [
          "transformer.h.5.attn.c_proj"
        ]
      },
      "r37": {
        "r": 37,
        "modules": [
          "transformer.h.2.attn.c_proj",
          "transformer.h.4.attn.c_proj"
        ]
      },
      "r36": {
        "r": 36,
        "modules": [
          "transformer.h.3.attn.c_proj"
        ]
      },
      "r34": {
        "r": 34,
        "modules": [
          "transformer.h.23.mlp.c_proj"
        ]
      },
      "r31": {
        "r": 31,
        "modules": [
          "transformer.h.22.mlp.c_proj"
        ]
      },
      "r29": {
        "r": 29,
        "modules": [
          "transformer.h.21.mlp.c_proj"
        ]
      },
      "r27": {
        "r": 27,
        "modules": [
          "transformer.h.20.mlp.c_proj"
        ]
      },
      "r26": {
        "r": 26,
        "modules": [
          "transformer.h.19.mlp.c_proj"
        ]
      },
      "r24": {
        "r": 24,
        "modules": [
          "transformer.h.18.mlp.c_proj",
          "transformer.h.23.mlp.c_fc",
          "transformer.h.4.mlp.c_fc"
        ]
      },
      "r23": {
        "r": 23,
        "modules": [
          "transformer.h.1.mlp.c_fc",
          "transformer.h.17.mlp.c_proj"
        ]
      },
      "r22": {
        "r": 22,
        "modules": [
          "transformer.h.0.attn.c_proj",
          "transformer.h.15.mlp.c_proj",
          "transformer.h.16.mlp.c_proj",
          "transformer.h.5.mlp.c_fc"
        ]
      },
      "r21": {
        "r": 21,
        "modules": [
          "transformer.h.12.mlp.c_fc",
          "transformer.h.2.mlp.c_fc",
          "transformer.h.3.mlp.c_fc"
        ]
      },
      "r20": {
        "r": 20,
        "modules": [
          "transformer.h.0.mlp.c_fc",
          "transformer.h.1.mlp.c_proj",
          "transformer.h.12.mlp.c_proj",
          "transformer.h.13.mlp.c_proj"
        ]
      },
      "r19": {
        "r": 19,
        "modules": [
          "transformer.h.0.mlp.c_proj",
          "transformer.h.10.mlp.c_fc",
          "transformer.h.10.mlp.c_proj",
          "transformer.h.11.mlp.c_fc",
          "transformer.h.11.mlp.c_proj",
          "transformer.h.13.mlp.c_fc",
          "transformer.h.14.mlp.c_fc",
          "transformer.h.14.mlp.c_proj",
          "transformer.h.15.mlp.c_fc",
          "transformer.h.16.mlp.c_fc",
          "transformer.h.17.mlp.c_fc",
          "transformer.h.18.mlp.c_fc",
          "transformer.h.19.mlp.c_fc",
          "transformer.h.2.mlp.c_proj",
          "transformer.h.20.mlp.c_fc",
          "transformer.h.21.mlp.c_fc",
          "transformer.h.22.mlp.c_fc",
          "transformer.h.3.mlp.c_proj",
          "transformer.h.4.mlp.c_proj",
          "transformer.h.5.mlp.c_proj",
          "transformer.h.6.mlp.c_fc",
          "transformer.h.6.mlp.c_proj",
          "transformer.h.7.mlp.c_fc",
          "transformer.h.7.mlp.c_proj",
          "transformer.h.8.mlp.c_fc",
          "transformer.h.8.mlp.c_proj",
          "transformer.h.9.mlp.c_fc",
          "transformer.h.9.mlp.c_proj"
        ]
      }
    }
  },
  "block_size": 256,
  "epochs": 1,
  "batch_size": 8,
  "grad_accum": 2,
  "lr": 0.0002
}